{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Mixing Investigation in mHC\n",
    "\n",
    "This notebook runs experiments to investigate whether doubly stochastic H_res matrices in mHC exhibit Markov chain mixing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional - for saving checkpoints)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/tokenbender/mHC-manifold-constrained-hyper-connections.git\n",
    "%cd mHC-manifold-constrained-hyper-connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -e . --quiet\n",
    "!pip install wandb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all Markov mixing tests\n",
    "!pytest tests/test_markov_mixing.py -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run existing HC tests to make sure nothing broke\n",
    "!pytest tests/test_hyper_connections.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Sanity Check (No Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test spectral analysis functions directly\n",
    "import torch\n",
    "from hyper_connections.hyper_connections import sinkhorn_log\n",
    "from analysis.spectral import analyze_h_res, spectral_gap\n",
    "from analysis.markov_metrics import cumulative_product_metrics\n",
    "\n",
    "# Create some random H_res matrices\n",
    "num_layers = 12\n",
    "num_streams = 4\n",
    "\n",
    "h_res_list = []\n",
    "for i in range(num_layers):\n",
    "    logits = torch.randn(num_streams, num_streams)\n",
    "    H = sinkhorn_log(logits, num_iters=10, tau=0.05)\n",
    "    h_res_list.append(H)\n",
    "    \n",
    "    props = analyze_h_res(H)\n",
    "    print(f\"Layer {i}: |λ₂|={props['lambda_2_abs']:.4f}, gap={props['spectral_gap']:.4f}\")\n",
    "\n",
    "print(\"\\n--- Cumulative Product Analysis ---\")\n",
    "metrics = cumulative_product_metrics(h_res_list)\n",
    "for i in range(len(metrics['dist_to_uniform'])):\n",
    "    print(f\"Depth {i}: dist_to_uniform={metrics['dist_to_uniform'][i]:.4f}, gap={metrics['spectral_gap'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download FineWeb10B Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd examples/nanogpt\n",
    "!python data/fineweb10B/download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Baseline Characterization\n",
    "\n",
    "Train a 6-layer mHC model to establish baseline spectral properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Login to W&B\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 6-layer mHC baseline (quick test - 500 iters)\n",
    "!python train.py config/train_fineweb10B_mhc.py \\\n",
    "    max_iters=500 \\\n",
    "    eval_interval=100 \\\n",
    "    spectral_log_interval=100 \\\n",
    "    out_dir=\"out-mhc-baseline-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the checkpoint\n",
    "!python ../../scripts/analyze_checkpoint.py --checkpoint out-mhc-baseline-test/ckpt.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Training Run (6-layer baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full 5000 iteration training\n",
    "!python train.py config/train_fineweb10B_mhc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the trained checkpoint\n",
    "!python ../../scripts/analyze_checkpoint.py \\\n",
    "    --checkpoint out-fineweb10B-mhc/ckpt.pt \\\n",
    "    --output ../../analysis_results/baseline_6l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual-Only Ablation\n",
    "\n",
    "Test whether H_pre/H_post injections compensate for mixing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train residual-only variant\n",
    "!python train.py config/train_fineweb10B_mhc_resonly.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze residual-only checkpoint\n",
    "!python ../../scripts/analyze_checkpoint.py \\\n",
    "    --checkpoint out-fineweb10B-mhc-resonly/ckpt.pt \\\n",
    "    --output ../../analysis_results/resonly_6l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 48-Layer Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 48-layer mHC\n",
    "!python train.py config/train_fineweb10B_mhc_48l.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze 48-layer checkpoint\n",
    "!python ../../scripts/analyze_checkpoint.py \\\n",
    "    --checkpoint out-fineweb10B-mhc-48l/ckpt.pt \\\n",
    "    --output ../../analysis_results/mhc_48l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Sinkhorn vs Orthostochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with orthostochastic projection\n",
    "!python train.py config/train_fineweb10B_mhc.py \\\n",
    "    mhc_h_res_proj=\"orthostochastic\" \\\n",
    "    out_dir=\"out-mhc-orthostochastic\" \\\n",
    "    wandb_run_name=\"mhc-orthostochastic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze orthostochastic checkpoint\n",
    "!python ../../scripts/analyze_checkpoint.py \\\n",
    "    --checkpoint out-mhc-orthostochastic/ckpt.pt \\\n",
    "    --projection orthostochastic \\\n",
    "    --output ../../analysis_results/orthostochastic_6l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Analysis\n",
    "\n",
    "Run analysis directly in Python for more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from hyper_connections.hyper_connections import sinkhorn_log\n",
    "from analysis.spectral import analyze_h_res\n",
    "from analysis.markov_metrics import cumulative_product_metrics\n",
    "\n",
    "def load_and_analyze(checkpoint_path, projection='sinkhorn'):\n",
    "    \"\"\"Load checkpoint and run full analysis.\"\"\"\n",
    "    ckpt = torch.load(checkpoint_path, map_location='cpu')\n",
    "    state_dict = ckpt['model']\n",
    "    \n",
    "    # Extract H_res matrices\n",
    "    h_res_keys = sorted([k for k in state_dict if 'H_res_logits' in k])\n",
    "    h_res_list = []\n",
    "    per_layer = {}\n",
    "    \n",
    "    for i, key in enumerate(h_res_keys):\n",
    "        logits = state_dict[key]\n",
    "        H = sinkhorn_log(logits, 10, 0.05)\n",
    "        h_res_list.append(H)\n",
    "        per_layer[i] = analyze_h_res(H)\n",
    "    \n",
    "    cumulative = cumulative_product_metrics(h_res_list)\n",
    "    \n",
    "    return per_layer, cumulative, h_res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "def plot_mixing_analysis(per_layer, cumulative):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Per-layer |λ₂|\n",
    "    ax = axes[0, 0]\n",
    "    lambda2s = [per_layer[i]['lambda_2_abs'] for i in sorted(per_layer.keys())]\n",
    "    ax.plot(lambda2s, 'o-')\n",
    "    ax.axhline(y=0.9, color='g', linestyle='--', label='Near-permutation threshold')\n",
    "    ax.axhline(y=0.7, color='orange', linestyle='--', label='Moderate mixing threshold')\n",
    "    ax.set_xlabel('Layer')\n",
    "    ax.set_ylabel('|λ₂|')\n",
    "    ax.set_title('Second Eigenvalue per Layer')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    \n",
    "    # Cumulative distance to uniform\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(cumulative['dist_to_uniform'], 'o-')\n",
    "    ax.set_xlabel('Depth (cumulative layers)')\n",
    "    ax.set_ylabel('Frobenius distance')\n",
    "    ax.set_title('Distance to Uniform Matrix')\n",
    "    \n",
    "    # Cumulative spectral gap\n",
    "    ax = axes[1, 0]\n",
    "    ax.plot(cumulative['spectral_gap'], 'o-')\n",
    "    ax.set_xlabel('Depth (cumulative layers)')\n",
    "    ax.set_ylabel('Spectral gap')\n",
    "    ax.set_title('Cumulative Product Spectral Gap')\n",
    "    \n",
    "    # Per-layer entropy\n",
    "    ax = axes[1, 1]\n",
    "    entropies = [per_layer[i]['entropy'] for i in sorted(per_layer.keys())]\n",
    "    ax.plot(entropies, 'o-')\n",
    "    ax.set_xlabel('Layer')\n",
    "    ax.set_ylabel('Entropy')\n",
    "    ax.set_title('Matrix Entropy per Layer')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Example usage (uncomment after training):\n",
    "# per_layer, cumulative, h_res_list = load_and_analyze('out-fineweb10B-mhc/ckpt.pt')\n",
    "# plot_mixing_analysis(per_layer, cumulative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize H_res Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_h_res_heatmaps(h_res_list, max_show=12):\n",
    "    \"\"\"Visualize H_res matrices as heatmaps.\"\"\"\n",
    "    n_show = min(len(h_res_list), max_show)\n",
    "    cols = 4\n",
    "    rows = (n_show + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(3*cols, 3*rows))\n",
    "    axes = axes.flatten() if n_show > 1 else [axes]\n",
    "    \n",
    "    for i in range(n_show):\n",
    "        ax = axes[i]\n",
    "        H = h_res_list[i].numpy()\n",
    "        im = ax.imshow(H, cmap='Blues', vmin=0, vmax=1)\n",
    "        ax.set_title(f'Layer {i}')\n",
    "        ax.set_xticks(range(H.shape[0]))\n",
    "        ax.set_yticks(range(H.shape[0]))\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_show, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (uncomment after training):\n",
    "# plot_h_res_heatmaps(h_res_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Multiple Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_checkpoints(checkpoint_paths, labels):\n",
    "    \"\"\"Compare mixing behavior across multiple checkpoints.\"\"\"\n",
    "    results = {}\n",
    "    for path, label in zip(checkpoint_paths, labels):\n",
    "        try:\n",
    "            per_layer, cumulative, _ = load_and_analyze(path)\n",
    "            results[label] = {\n",
    "                'per_layer': per_layer,\n",
    "                'cumulative': cumulative\n",
    "            }\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Checkpoint not found: {path}\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No checkpoints found!\")\n",
    "        return\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Compare cumulative distance to uniform\n",
    "    ax = axes[0]\n",
    "    for label, data in results.items():\n",
    "        ax.plot(data['cumulative']['dist_to_uniform'], 'o-', label=label)\n",
    "    ax.set_xlabel('Depth')\n",
    "    ax.set_ylabel('Distance to Uniform')\n",
    "    ax.set_title('Cumulative Mixing Comparison')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Compare avg |λ₂| per layer\n",
    "    ax = axes[1]\n",
    "    for label, data in results.items():\n",
    "        lambda2s = [data['per_layer'][i]['lambda_2_abs'] \n",
    "                    for i in sorted(data['per_layer'].keys())]\n",
    "        ax.plot(lambda2s, 'o-', label=label)\n",
    "    ax.axhline(y=0.9, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Layer')\n",
    "    ax.set_ylabel('|λ₂|')\n",
    "    ax.set_title('Per-Layer Second Eigenvalue')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (uncomment after training multiple models):\n",
    "# compare_checkpoints(\n",
    "#     ['out-fineweb10B-mhc/ckpt.pt', 'out-fineweb10B-mhc-48l/ckpt.pt'],\n",
    "#     ['6-layer', '48-layer']\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
